# Week 11: Ensemble Learning Methods
---

**Table of Content**
- [Week 11: Ensemble Learning Methods](#week-11-ensemble-learning-methods)
  - [Objectives](#objectives)
  - [Topics](#topics)
  - [Course materials](#course-materials)
  - [Suggested reading](#suggested-reading)

---
## Objectives
In this week, we will wrap up the previous demo of credit risk predictions, cover some additional topics on ensemble learning and explore the landscape of ensemble learning methods.

## Topics
Here are the topics we are going to cover
* [ ] Ensemble learning
  * [ ] Voting
  * [ ] Bagging
  * [ ] Boosting
    * [ ] Adaboost
    * [ ] Gradient Boosting
  * [ ] Stacking


## Course materials
* slides [[link](TBD)]

## Suggested reading
* **Chapter 7** of *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition*
* Introduction to Boosted Trees [[link](https://xgboost.readthedocs.io/en/stable/tutorials/model.html)]
* Understanding Gradient Boosting as a Gradient Descent [[link](https://nicolas-hug.com/blog/gradient_boosting_descent)]
* Machine Learning for an explainable cost prediction of medical insurance [[link](https://www.sciencedirect.com/science/article/pii/S2666827023000695?via%3Dihub)]