{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Click the icon below to open this notebook in Colab**)\n",
    "\n",
    "[![Open InColab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiangshiyin/machine-learning-for-actuarial-science/blob/main/2025-spring/week05/notebook/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the Titanic datasets from Kaggle.\n",
    "https://www.kaggle.com/competitions/titanic/data\n",
    "- **The Titanic** https://en.wikipedia.org/wiki/Titanic\n",
    "\n",
    "| Variable   | Definition                                | Key                                  |\n",
    "|------------|-------------------------------------------|--------------------------------------|\n",
    "| survival   | Survival                                 | 0 = No, 1 = Yes                     |\n",
    "| pclass     | Ticket class                             | 1 = 1st, 2 = 2nd, 3 = 3rd           |\n",
    "| sex        | Sex                                      |                                      |\n",
    "| Age        | Age in years                             |                                      |\n",
    "| sibsp      | # of siblings / spouses aboard the Titanic |                                      |\n",
    "| parch      | # of parents / children aboard the Titanic |                                      |\n",
    "| ticket     | Ticket number                            |                                      |\n",
    "| fare       | Passenger fare                           |                                      |\n",
    "| cabin      | Cabin number                             |                                      |\n",
    "| embarked   | Port of Embarkation                     | C = Cherbourg, Q = Queenstown, S = Southampton |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/titanic/train.csv')\n",
    "test = pd.read_csv('../data/titanic/test.csv')\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define color palette for consistency\n",
    "palette = \"husl\"\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n",
    "\n",
    "# 1st row\n",
    "sns.countplot(x='Pclass', data=train, ax=axes[0, 0])\n",
    "sns.countplot(x='Sex', data=train, ax=axes[0, 1])\n",
    "sns.countplot(x='Embarked', data=train, ax=axes[0, 2])\n",
    "\n",
    "# 2nd row\n",
    "sns.boxplot(x='Pclass', y='Age', data=train, ax=axes[1, 0])\n",
    "sns.histplot(train['Fare'].dropna(), ax=axes[1, 1], bins=30, color='b')\n",
    "sns.countplot(x='SibSp', hue='Survived', data=train, ax=axes[1,2], palette=palette)\n",
    "\n",
    "# 3rd row\n",
    "sns.countplot(x='Pclass', hue='Survived', data=train, ax=axes[2, 0], palette=palette)\n",
    "sns.countplot(x='Sex', hue='Survived', data=train, ax=axes[2, 1], palette=palette)\n",
    "sns.histplot(x='Age', hue='Survived', data=train, ax=axes[2, 2], bins=5, palette=palette)\n",
    "\n",
    "# 4th row\n",
    "sns.countplot(x='Parch', hue='Survived', data=train, ax=axes[3, 0], palette=palette)\n",
    "sns.stripplot(x='Pclass', y='Fare', hue='Survived', data=train, palette=palette, ax=axes[3, 1], jitter=True, dodge=True)\n",
    "sns.countplot(x='Embarked', hue='Survived', data=train, ax=axes[3, 2], palette=palette)\n",
    "\n",
    "# Set titles for each subplot\n",
    "titles = [\n",
    "    \"Total Passengers by Class\", \n",
    "    \"Total Passengers by Gender\", \n",
    "    \"Total Passengers by Embarked\", \n",
    "    \"Age Box Plot By Class\", \n",
    "    \"Fare Distribution\", \n",
    "    \"Survival Rate by SibSp\",\n",
    "    \"Survival Rate by Class\", \n",
    "    \"Survival Rate by Gender\", \n",
    "    \"Survival Rate by Age\", \n",
    "    \"Survival Rate by Parch\",\n",
    "    \"Survival Rate by Fare and Pclass\", \n",
    "    \"Survival Rate by Embarked\"\n",
    "]\n",
    "\n",
    "# Assign titles correctly\n",
    "for ax, title in zip(axes.flat, titles):\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Quick survey across key variables\n",
    "\n",
    "- Some quick analysis across key columns is usually a good starting point to help understand the data.\n",
    "- **Domain knowledge and common sense are important too!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all column names to lower cases\n",
    "train.columns = train.columns.str.lower()\n",
    "test.columns = test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are survived, also include the corresponding % out of the total\n",
    "\n",
    "dist_survived_train = train.groupby('survived')['passengerid'].count().reset_index()\n",
    "dist_survived_train['percentage'] = (dist_survived_train['passengerid'] / len(train)).map(lambda x: round(x, 4))\n",
    "dist_survived_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good to know that the train and test datasets have consistent data distributions!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['pclass'].head(5)\n",
    "train.groupby('pclass')['passengerid'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('pclass')['passengerid'].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `Pclass` here represents the passenger class, which indicates the socio-economic status (SES) of the passenger based on their ticket type.\n",
    "\n",
    "| Pclass | Description   | Socio-Economic Status     |\n",
    "|--------|-------------|--------------------------|\n",
    "| 1      | First Class  | Upper Class (Wealthy)    |\n",
    "| 2      | Second Class | Middle Class             |\n",
    "| 3      | Third Class  | Lower Class (Poorer)     |\n",
    "\n",
    "- First class passengers were given priority boarding, access to a higher deck, and potentially the priority in evacuation\n",
    "- Third class passengers were mostly in lower deck areas, making it harder to reach lifeboats\n",
    "\n",
    "![](https://rpmarchildon.com/wp-content/uploads/2018/06/titanic_class_cabin_locations.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let pandas display all rows instead of hidding\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "train.groupby(['pclass','embarked'])['passengerid'].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "![](https://d.newsweek.com/en/full/2248395/titanic-journey.jpg?w=1200&f=ea15a8ece59fe5cc42a6ab06fb1fb672)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('embarked')['passengerid'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cabin variable\n",
    "train['cabin'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.titanicandco.com/titanic/images/deckplan1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sex_train = train.groupby(['sex'])['passengerid'].count().reset_index()\n",
    "dist_sex_train['percentage'] = (dist_sex_train['passengerid'] / len(train)).map(lambda x: '{:.2%}'.format(x))\n",
    "dist_sex_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sex_test = test.groupby(['sex'])['passengerid'].count().reset_index()\n",
    "dist_sex_test['percentage'] = (dist_sex_test['passengerid'] / len(test)).map(lambda x: '{:.2%}'.format(x))\n",
    "dist_sex_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of other numerical features\n",
    "train[[\n",
    "    'age',\n",
    "    'sibsp',\n",
    "    'parch',\n",
    "    'fare'\n",
    "]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\n",
    "    'age',\n",
    "    'sibsp',\n",
    "    'parch',\n",
    "    'fare'\n",
    "]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticket number??\n",
    "\n",
    "train['ticket'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Raw Ticket values are not directly useful because they are alphanumeric and contain no obvious numerical meaning.\n",
    "- However, feature engineering can extract useful patterns that might impact survival probability.\n",
    "- Possible insights:\n",
    "  - Passengers with the same ticket number likely traveled together, which can indicate family or group survival dependencies.\n",
    "  - Ticket prefixes might correlate with cabin class or embarkation location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Outlier detection\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/1*0MPDTLn8KoLApoFvI0P2vQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Outlier detection \n",
    "def detect_outliers(df,n,features):\n",
    "    outlier_indices = []\n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col],25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col],75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index       \n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "        \n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n",
    "    return multiple_outliers   \n",
    "# detect outliers from Age, SibSp , Parch and Fare\n",
    "outliers_to_drop = detect_outliers(train,2,[\"age\",\"sibsp\",\"parch\",\"fare\"])\n",
    "train.loc[outliers_to_drop] # Show the outliers rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "# train = train.drop(outliers_to_drop, axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Handle Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, there are missing values in the following columns:\n",
    "- `Age`\n",
    "- `Cabin`\n",
    "- `Embarked`\n",
    "\n",
    "Missing values are typically bad and need to be handled. However, some algorithms can handle missing values, such as decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to quickly locate columns with null values??\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Reason                                     | Who Is Affected?               |\n",
    "|--------------------------------------------|--------------------------------|\n",
    "| Poor record-keeping (pre-1912 era)         | Mostly third-class passengers  |\n",
    "| Ticketing system didn’t require age        | Families, group travelers      |\n",
    "| Crew members not consistently recorded     | Crew entries in the dataset    |\n",
    "| Passengers may have hidden or omitted age  | Various                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values in age with the median age\n",
    "train['age'] = train['age'].fillna(train['age'].median())\n",
    "test['age'] = test['age'].fillna(test['age'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First-class passengers had private cabins, which were recorded.\n",
    "- Some second-class passengers also had assigned cabins, but not all.\n",
    "- Most third-class passengers didn’t have individual cabins but instead stayed in large dormitory-style areas (especially in the lower decks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_cabin'] = train['cabin'].notna().astype(int)\n",
    "train.groupby('pclass')['has_cabin'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Feature Engineering\n",
    "\n",
    "Here are the general types of data we could encounter:\n",
    "- **Categorical data**:\n",
    "  - With ordinal relationships - e.g., ratings, grades\n",
    "  - Without ordinal relationships - e.g., colors, brands\n",
    "- **Numerical data**:\n",
    "  - Discrete - e.g., number of children, number of votes\n",
    "  - Continuous - e.g., height, weight, temperature\n",
    "\n",
    "Ultimately, we want to convert all data into numerical data for computation, which means that we need to convert categorical data into numerical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding ordinal variables\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df = pd.DataFrame({'education': ['primary', 'secondary', 'tertiary', 'primary']})\n",
    "encoder = OrdinalEncoder(categories=[['primary', 'secondary', 'tertiary']])  # Define order\n",
    "\n",
    "df['education_encoded'] = encoder.fit_transform(df[['education']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_arr = encoder.fit_transform(df[['education']])\n",
    "encoded_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_arr = pd.DataFrame(encoded_arr, columns=encoder.get_feature_names_out(['education']))\n",
    "df_encoded_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sex.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sex'] = train['sex'].map( {'female': 0, 'male': 1} ).astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Normalize numerical variables\n",
    "\n",
    "| **Transformation**        | **Description**                                         | **Method**             |\n",
    "|---------------------------|---------------------------------------------------------|------------------------|\n",
    "| Normalization             | Scales to [0, 1] range                                  | `MinMaxScaler()`       |\n",
    "| Standardization           | Scales to have mean 0, std 1                            | `StandardScaler()`     |\n",
    "| Log Transformation        | Compresses large values, reduces skewness               | `np.log()`             |\n",
    "| [Box-Cox Transformation](https://builtin.com/data-science/box-cox-transformation-target-variable)    | Stabilizes variance and normalizes data                 | `stats.boxcox()` [[reference](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html)]      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame({'Age': [22, 38, 26, 35, 35, 54, 2],\n",
    "                   'Fare': [7.25, 71.2833, 7.925, 53.1, 8.05, 51.8625, 21.075]})\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the numerical data\n",
    "df_normalized = df.copy()\n",
    "df_normalized[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
    "\n",
    "df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize the numerical data\n",
    "df_standardized = df.copy()\n",
    "df_standardized[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
    "\n",
    "df_standardized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transformation - right skewed data\n",
    "import numpy as np\n",
    "\n",
    "# Apply log transformation (for positive values)\n",
    "df_transformed = df.copy()\n",
    "df_transformed['Fare_log'] = np.log(df_transformed['Fare'] + 1)  # Added 1 to avoid log(0)\n",
    "\n",
    "df_transformed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box-Cox transformation\n",
    "from scipy import stats\n",
    "\n",
    "# Apply Box-Cox transformation (only for positive values)\n",
    "df_boxcox = df.copy()\n",
    "df_boxcox['Fare_boxcox'], _ = stats.boxcox(df_boxcox['Fare'] + 1)  # Added 1 to avoid 0 values\n",
    "\n",
    "df_boxcox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Create meaningful features\n",
    "\n",
    "Sometimes, we could combine or repurpose existing features to create new features that have a stronger correlation with the target variable. The **correlation analysis** between the explainatory variables and the target variable is typically the criteria for evaluating the usefulness of a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `embarked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('embarked')['survived'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='embarked', y='survived', data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"embarked\", y=\"survived\", hue=\"sex\", data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['name']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['name_length'] = train['name'].map(len)\n",
    "train[['name', 'name_length']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('name_length')['passengerid'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['name_length'] = train['name'].map(len)\n",
    "passenger_count = train.groupby(['name_length'])['passengerid'].count().reset_index().rename(columns={'passengerid':'num_passengers'})\n",
    "survival_dist = train.groupby(['name_length'])['survived'].mean().reset_index()\n",
    "fig, (axis1,axis2,axis3) = plt.subplots(3,1,figsize=(18,6))\n",
    "sns.barplot(x='name_length', y='num_passengers', data=passenger_count, ax = axis1)\n",
    "sns.barplot(x='name_length', y='survived', data=survival_dist, ax = axis2)\n",
    "sns.pointplot(x='name_length', y='survived', data=survival_dist, ax = axis3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['name_length_cat'] = train['name_length'].apply(lambda x: 0 if x <= 23 else 1 if x <= 28 else 2 if x <= 40 else 3)\n",
    "train['name_length_cat'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot distributions of age of passengers who survived or did not survive\n",
    "sns.kdeplot(x='age', data=train, hue='survived', common_norm=False)\n",
    "# sns.displot(x='age', data=train, hue='survived', kind='kde', common_norm=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_cat'] = train['age'].apply(\n",
    "    lambda x: 0 if x <= 14 else 1 if x <= 30 else 2 if x <= 40 else 3 if x <= 50 else 4 if x <= 60 else 5\n",
    ")\n",
    "train.age_cat.value_counts().reset_index() #.sort_values(by='age_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(['age_cat'])['survived'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `familysize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['family_size'] = train['sibsp'] + train['parch'] + 1\n",
    "train['is_alone'] = train['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18,6))\n",
    "sns.barplot(x='family_size', y='survived', hue='sex', data=train, ax=axes[0])\n",
    "sns.barplot(x='is_alone', y='survived', hue='sex', data=train, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fare`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='fare', data=train, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log to Fare to reduce skewness distribution\n",
    "train[\"fare_log\"] = train[\"fare\"].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "\n",
    "sns.kdeplot(x='fare_log', data=train, hue='survived', common_norm=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['fare_log_cat'] = train['fare_log'].apply(\n",
    "    lambda x: 0 if x <= 2.7 else 1 if x <= 3.2 else 2 if x <= 3.6 else 3\n",
    ")\n",
    "train['fare_log_cat'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `cabin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['has_cabin'] = train['cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "train.groupby('has_cabin')['survived'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    " # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train['title'] = train['name'].apply(get_title)\n",
    "\n",
    "fig, (axis1) = plt.subplots(1,figsize=(18,6))\n",
    "sns.barplot(x=\"title\", y=\"survived\", data=train, ax=axis1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `deck`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['cabin']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "\n",
    "train['cabin'] = train['cabin'].fillna(\"U0\")\n",
    "train['deck'] = train['cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "train['deck'] = train['deck'].map(deck)\n",
    "train['deck'] = train['deck'].fillna(0)\n",
    "train['deck'] = train['deck'].astype(int)\n",
    "\n",
    "train.deck.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'deck', y = 'survived', order=[1,2,3,4,5,6,7,8], data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colormap = plt.cm.RdBu\n",
    "# plt.figure(figsize=(14,12))\n",
    "# plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "# sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Fare',\n",
    "#        u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n",
    "# g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
