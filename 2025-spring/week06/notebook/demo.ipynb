{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Click the icon below to open this notebook in Colab**)\n",
    "\n",
    "[![Open InColab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiangshiyin/machine-learning-for-actuarial-science/blob/main/2025-spring/week06/notebook/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In our last class, we explored the Titanic dataset, examined it from multiple perspectives, and applied various feature engineering techniques to enhance its explanatory variables. Today, we will continue working with the Titanic dataset, focusing on model training and evaluation techniques to gain deeper insights into predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic/data\n",
    "- **The Titanic** https://en.wikipedia.org/wiki/Titanic\n",
    "\n",
    "| Variable   | Definition                                | Key                                  |\n",
    "|------------|-------------------------------------------|--------------------------------------|\n",
    "| survival   | Survival                                 | 0 = No, 1 = Yes                     |\n",
    "| pclass     | Ticket class                             | 1 = 1st, 2 = 2nd, 3 = 3rd           |\n",
    "| sex        | Sex                                      |                                      |\n",
    "| Age        | Age in years                             |                                      |\n",
    "| sibsp      | # of siblings / spouses aboard the Titanic |                                      |\n",
    "| parch      | # of parents / children aboard the Titanic |                                      |\n",
    "| ticket     | Ticket number                            |                                      |\n",
    "| fare       | Passenger fare                           |                                      |\n",
    "| cabin      | Cabin number                             |                                      |\n",
    "| embarked   | Port of Embarkation                     | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/titanic/train.csv')\n",
    "test = pd.read_csv('../data/titanic/test.csv')\n",
    "\n",
    "# convert all column names to lower cases\n",
    "train.columns = train.columns.str.lower()\n",
    "test.columns = test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                name     sex   age  sibsp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   parch            ticket     fare cabin embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Streamline the data transformations\n",
    "\n",
    "Here are the data exploration and transformation strategies we used so far:\n",
    "* Quick survey across key variables\n",
    "* Detect and address data anomalies\n",
    "  * Missing values\n",
    "  * Outliers\n",
    "* Feature engineering\n",
    "  * Encode categorical variables\n",
    "  * Normalize numerical variables\n",
    "  * Create new features with stronger predictive power\n",
    "\n",
    "Data exploration process is typically iterative and complex. Once we have a good understanding of the data and some potential strategies to apply in the feature engineering process, we need to make sure these transformation strategies can be easily and consistently applied to new datasets, such as the test set and new batches of data for model retraining. This requires a systematic approach to streamline the data transformations so that we don't need to start from scratch and repeat the same steps for each new dataset. This is especially important in the real-world scenario where we want to productionalize and automate the data transformation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_num_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values in numerical columns of a DataFrame using the median of each column.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The DataFrame to impute missing values in.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select only the numerical columns\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Impute missing values with the median of each column\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age              0\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = impute_missing_num_values(train)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables could have missing values too\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html\n",
    "\n",
    "def impute_missing_cat_values(df, ignore_list):\n",
    "    \"\"\"\n",
    "    Impute missing categorical values with the most frequent value.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        ignore_list (list): List of column names to ignore.    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with imputed missing categorical values.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ignore_list:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age              0\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = impute_missing_cat_values(train, ignore_list=['cabin'])\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Attention:** We will treat the missing values in `cabin` in the feature engineering step!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Encode categorical features\n",
    "- Normalize numerical features\n",
    "- Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'sex', 'ticket', 'cabin', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "# The categorical variables in the datasets\n",
    "\n",
    "cat_cols = [\n",
    "    col\n",
    "    for col in train.columns if train[col].dtype == \"object\"\n",
    "] \n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply onehot encoding to the categorical columns\n",
    "# use the sklearn library\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def onehot_encode(df, ignore_list):\n",
    "    cat_cols = [\n",
    "        col for col in df.columns if col not in ignore_list and df[col].dtype == 'object'\n",
    "    ]\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded = encoder.fit_transform(df[cat_cols])\n",
    "    encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    df = df.drop(cat_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = onehot_encode(train, ignore_list=['cabin', 'name', 'ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform numeric features, log transform `fare`\n",
    "import numpy as np\n",
    "\n",
    "def log_transform(df, features, drop=False):\n",
    "    for feature in features:\n",
    "        df[feature+'_log'] = np.log1p(df[feature]) \n",
    "    if drop:\n",
    "        df = df.drop(features, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'age', 'sibsp', 'parch',\n",
       "       'ticket', 'fare', 'cabin', 'sex_female', 'sex_male', 'embarked_C',\n",
       "       'embarked_Q', 'embarked_S', 'fare_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = log_transform(train, features=['fare'])\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "import re\n",
    "\n",
    "def create_features(df):\n",
    "    df['has_cabin'] = df['cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = df['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['title'] = df['name'].apply(lambda x: re.search('([A-Z][a-z]+)\\\\.', x).group(1))\n",
    "    df['cabin'] = df['cabin'].fillna('U0')\n",
    "    df['deck'] = df['cabin'].apply(lambda x: re.search('([A-Z]+)', x).group(1))\n",
    "    df['name_len_cat'] = df['name'].apply(lambda x: 0 if len(x) <= 23 else 1 if len(x) <= 28 else 2 if len(x) <= 40 else 3)\n",
    "    df['age_cat'] = df['age'].apply(lambda x: 0 if x <= 14 else 1 if x <= 30 else 2 if x <= 40 else 3 if x <= 50 else 4 if x <= 60 else 5)\n",
    "    df['fare_log_cat'] = df['fare_log'].apply(lambda x: 0 if x <= 2.7 else 1 if x <= 3.2 else 2 if x <= 3.6 else 3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'age', 'sibsp', 'parch',\n",
       "       'ticket', 'fare', 'cabin', 'sex_female', 'sex_male', 'embarked_C',\n",
       "       'embarked_Q', 'embarked_S', 'fare_log', 'has_cabin', 'family_size',\n",
       "       'is_alone', 'title', 'deck', 'name_len_cat', 'age_cat', 'fare_log_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = create_features(train)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def impute_missing_num_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values in numerical columns of a DataFrame using the median of each column.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The DataFrame to impute missing values in.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select only the numerical columns\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Impute missing values with the median of each column\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def impute_missing_cat_values(df, ignore_list):\n",
    "    \"\"\"\n",
    "    Impute missing categorical values with the most frequent value.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        ignore_list (list): List of column names to ignore.    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with imputed missing categorical values.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ignore_list:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, features, drop=False):\n",
    "    for feature in features:\n",
    "        df[feature+'_log'] = np.log1p(df[feature]) \n",
    "    if drop:\n",
    "        df = df.drop(features, axis=1)\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    df['has_cabin'] = df['cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = df['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['title'] = df['name'].apply(lambda x: re.search('([A-Z][a-z]+)\\\\.', x).group(1))\n",
    "    df['cabin'] = df['cabin'].fillna('U0')\n",
    "    df['deck'] = df['cabin'].apply(lambda x: re.search('([A-Z]+)', x).group(1))\n",
    "    df['name_len_cat'] = df['name'].apply(lambda x: 0 if len(x) <= 23 else 1 if len(x) <= 28 else 2 if len(x) <= 40 else 3)\n",
    "    df['age_cat'] = df['age'].apply(lambda x: 0 if x <= 14 else 1 if x <= 30 else 2 if x <= 40 else 3 if x <= 50 else 4 if x <= 60 else 5)\n",
    "    df['fare_log_cat'] = df['fare_log'].apply(lambda x: 0 if x <= 2.7 else 1 if x <= 3.2 else 2 if x <= 3.6 else 3)\n",
    "    return df\n",
    "\n",
    "def load_data():\n",
    "    train = pd.read_csv('../data/titanic/train.csv')\n",
    "    test = pd.read_csv('../data/titanic/test.csv')\n",
    "    # convert all column names to lower cases\n",
    "    train.columns = train.columns.str.lower()\n",
    "    test.columns = test.columns.str.lower()    \n",
    "    return train, test\n",
    "\n",
    "def transform_data(df, encoder=None):\n",
    "    df = impute_missing_num_values(df)\n",
    "    df = impute_missing_cat_values(df, ['cabin', 'embarked'])\n",
    "    df = log_transform(df, ['fare'])\n",
    "    df = create_features(df)\n",
    "    \n",
    "    cat_attributes = ['sex', 'embarked', 'title', 'deck']\n",
    "    if not encoder:\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        encoder.fit(df[cat_attributes])\n",
    "    encoded = encoder.transform(df[cat_attributes])\n",
    "    df = pd.concat([df, pd.DataFrame(encoded, columns=encoder.get_feature_names_out(cat_attributes))], axis=1)\n",
    "    # drop columns that are not needed\n",
    "    df = df.drop([\n",
    "        'name', 'ticket', 'cabin', 'fare'\n",
    "        # , 'age', 'fare', 'sibsp', 'parch'\n",
    "    ] + cat_attributes, axis=1)\n",
    "    return df, encoder\n",
    "\n",
    "train, test = load_data()\n",
    "train, encoder = transform_data(train)\n",
    "test, _ = transform_data(test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare_log</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>name_len_cat</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>fare_log_cat</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>embarked_nan</th>\n",
       "      <th>title_Capt</th>\n",
       "      <th>title_Col</th>\n",
       "      <th>title_Countess</th>\n",
       "      <th>title_Don</th>\n",
       "      <th>title_Dr</th>\n",
       "      <th>title_Jonkheer</th>\n",
       "      <th>title_Lady</th>\n",
       "      <th>title_Major</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mlle</th>\n",
       "      <th>title_Mme</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Ms</th>\n",
       "      <th>title_Rev</th>\n",
       "      <th>title_Sir</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass   age  sibsp  parch  fare_log  has_cabin  \\\n",
       "0            1         0       3  22.0      1      0  2.110213          0   \n",
       "1            2         1       1  38.0      1      0  4.280593          1   \n",
       "\n",
       "   family_size  is_alone  name_len_cat  age_cat  fare_log_cat  sex_female  \\\n",
       "0            2         0             0        1             0         0.0   \n",
       "1            2         0             3        2             3         1.0   \n",
       "\n",
       "   sex_male  embarked_C  embarked_Q  embarked_S  embarked_nan  title_Capt  \\\n",
       "0       1.0         0.0         0.0         1.0           0.0         0.0   \n",
       "1       0.0         1.0         0.0         0.0           0.0         0.0   \n",
       "\n",
       "   title_Col  title_Countess  title_Don  title_Dr  title_Jonkheer  title_Lady  \\\n",
       "0        0.0             0.0        0.0       0.0             0.0         0.0   \n",
       "1        0.0             0.0        0.0       0.0             0.0         0.0   \n",
       "\n",
       "   title_Major  title_Master  title_Miss  title_Mlle  title_Mme  title_Mr  \\\n",
       "0          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "1          0.0           0.0         0.0         0.0        0.0       0.0   \n",
       "\n",
       "   title_Mrs  title_Ms  title_Rev  title_Sir  deck_A  deck_B  deck_C  deck_D  \\\n",
       "0        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "1        1.0       0.0        0.0        0.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "   deck_E  deck_F  deck_G  deck_T  deck_U  \n",
       "0     0.0     0.0     0.0     0.0     1.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 44)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare_log</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>name_len_cat</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>fare_log_cat</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>embarked_nan</th>\n",
       "      <th>title_Capt</th>\n",
       "      <th>title_Col</th>\n",
       "      <th>title_Countess</th>\n",
       "      <th>title_Don</th>\n",
       "      <th>title_Dr</th>\n",
       "      <th>title_Jonkheer</th>\n",
       "      <th>title_Lady</th>\n",
       "      <th>title_Major</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mlle</th>\n",
       "      <th>title_Mme</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Ms</th>\n",
       "      <th>title_Rev</th>\n",
       "      <th>title_Sir</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  pclass   age  sibsp  parch  fare_log  has_cabin  family_size  \\\n",
       "0          892       3  34.5      0      0  2.178064          0            1   \n",
       "1          893       3  47.0      1      0  2.079442          0            2   \n",
       "2          894       2  62.0      0      0  2.369075          0            1   \n",
       "\n",
       "   is_alone  name_len_cat  age_cat  fare_log_cat  sex_female  sex_male  \\\n",
       "0         1             0        2             0         0.0       1.0   \n",
       "1         0             2        3             0         1.0       0.0   \n",
       "2         1             1        5             0         0.0       1.0   \n",
       "\n",
       "   embarked_C  embarked_Q  embarked_S  embarked_nan  title_Capt  title_Col  \\\n",
       "0         0.0         1.0         0.0           0.0         0.0        0.0   \n",
       "1         0.0         0.0         1.0           0.0         0.0        0.0   \n",
       "2         0.0         1.0         0.0           0.0         0.0        0.0   \n",
       "\n",
       "   title_Countess  title_Don  title_Dr  title_Jonkheer  title_Lady  \\\n",
       "0             0.0        0.0       0.0             0.0         0.0   \n",
       "1             0.0        0.0       0.0             0.0         0.0   \n",
       "2             0.0        0.0       0.0             0.0         0.0   \n",
       "\n",
       "   title_Major  title_Master  title_Miss  title_Mlle  title_Mme  title_Mr  \\\n",
       "0          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "1          0.0           0.0         0.0         0.0        0.0       0.0   \n",
       "2          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "\n",
       "   title_Mrs  title_Ms  title_Rev  title_Sir  deck_A  deck_B  deck_C  deck_D  \\\n",
       "0        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "1        1.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "2        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   deck_E  deck_F  deck_G  deck_T  deck_U  \n",
       "0     0.0     0.0     0.0     0.0     1.0  \n",
       "1     0.0     0.0     0.0     0.0     1.0  \n",
       "2     0.0     0.0     0.0     0.0     1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshiyin/Documents/Teaching/machine-learning-for-actuarial-science/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# train a simple logistic regression model to predict the survival label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(\n",
    "    train.drop(columns=['survived', 'passengerid']), # everything except the survival label\n",
    "    train['survived'] # the survival label\n",
    ")\n",
    "\n",
    "pred = lr.predict(test.drop(columns=['passengerid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.concat([test['passengerid'], pd.DataFrame(pred, columns=['survived'])], axis=1)\n",
    "df_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('../data/titanic/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the prediction results\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic/overview/evaluation\n",
    "![](https://almablog-media.s3.ap-south-1.amazonaws.com/image_14_4f4fc2cf7d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived', 'passengerid'])\n",
    "y_train = train['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare_log</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>name_len_cat</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>fare_log_cat</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>embarked_nan</th>\n",
       "      <th>title_Capt</th>\n",
       "      <th>title_Col</th>\n",
       "      <th>title_Countess</th>\n",
       "      <th>title_Don</th>\n",
       "      <th>title_Dr</th>\n",
       "      <th>title_Jonkheer</th>\n",
       "      <th>title_Lady</th>\n",
       "      <th>title_Major</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mlle</th>\n",
       "      <th>title_Mme</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Ms</th>\n",
       "      <th>title_Rev</th>\n",
       "      <th>title_Sir</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass   age  sibsp  parch  fare_log  has_cabin  family_size  is_alone  \\\n",
       "0       3  22.0      1      0  2.110213          0            2         0   \n",
       "1       1  38.0      1      0  4.280593          1            2         0   \n",
       "\n",
       "   name_len_cat  age_cat  fare_log_cat  sex_female  sex_male  embarked_C  \\\n",
       "0             0        1             0         0.0       1.0         0.0   \n",
       "1             3        2             3         1.0       0.0         1.0   \n",
       "\n",
       "   embarked_Q  embarked_S  embarked_nan  title_Capt  title_Col  \\\n",
       "0         0.0         1.0           0.0         0.0        0.0   \n",
       "1         0.0         0.0           0.0         0.0        0.0   \n",
       "\n",
       "   title_Countess  title_Don  title_Dr  title_Jonkheer  title_Lady  \\\n",
       "0             0.0        0.0       0.0             0.0         0.0   \n",
       "1             0.0        0.0       0.0             0.0         0.0   \n",
       "\n",
       "   title_Major  title_Master  title_Miss  title_Mlle  title_Mme  title_Mr  \\\n",
       "0          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "1          0.0           0.0         0.0         0.0        0.0       0.0   \n",
       "\n",
       "   title_Mrs  title_Ms  title_Rev  title_Sir  deck_A  deck_B  deck_C  deck_D  \\\n",
       "0        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "1        1.0       0.0        0.0        0.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "   deck_E  deck_F  deck_G  deck_T  deck_U  \n",
       "0     0.0     0.0     0.0     0.0     1.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FLAML** - https://github.com/microsoft/FLAML/tree/main\n",
    "- `pip install flaml[automl]`\n",
    "- [Documentation](https://microsoft.github.io/FLAML/docs/Getting-Started)\n",
    "- Best practices [[link](https://learn.microsoft.com/en-us/fabric/data-science/automated-machine-learning-fabric#automl-workflow)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-16 15:45:14] {1728} INFO - task = classification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-16 15:45:14] {1739} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 02-16 15:45:14] {1838} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl.logger: 02-16 15:45:14] {1955} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'sgd', 'lrl1']\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2393} INFO - Estimated sufficient time budget=1398s. Estimated necessary time budget=32s.\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.3s,\testimator lgbm's best error=0.2189,\tbest estimator lgbm's best error=0.2189\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.3s,\testimator lgbm's best error=0.2189,\tbest estimator lgbm's best error=0.2189\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.4s,\testimator lgbm's best error=0.1728,\tbest estimator lgbm's best error=0.1728\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 3, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.6s,\testimator sgd's best error=0.3704,\tbest estimator lgbm's best error=0.1728\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.7s,\testimator lgbm's best error=0.1683,\tbest estimator lgbm's best error=0.1683\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.8s,\testimator lgbm's best error=0.1683,\tbest estimator lgbm's best error=0.1683\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.8s,\testimator lgbm's best error=0.1683,\tbest estimator lgbm's best error=0.1683\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 0.9s,\testimator lgbm's best error=0.1650,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 1.0s,\testimator lgbm's best error=0.1650,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2442} INFO -  at 1.1s,\testimator lgbm's best error=0.1650,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:15] {2258} INFO - iteration 10, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:16] {2442} INFO -  at 1.2s,\testimator sgd's best error=0.3704,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:16] {2258} INFO - iteration 11, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:16] {2442} INFO -  at 1.8s,\testimator sgd's best error=0.3199,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:16] {2258} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:16] {2442} INFO -  at 2.1s,\testimator xgboost's best error=0.2189,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:16] {2258} INFO - iteration 13, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2442} INFO -  at 2.2s,\testimator lgbm's best error=0.1650,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2258} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2442} INFO -  at 2.4s,\testimator xgboost's best error=0.2189,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2258} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2442} INFO -  at 2.5s,\testimator lgbm's best error=0.1650,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2258} INFO - iteration 16, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2442} INFO -  at 2.7s,\testimator extra_tree's best error=0.2043,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2258} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2442} INFO -  at 2.9s,\testimator extra_tree's best error=0.2043,\tbest estimator lgbm's best error=0.1650\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2258} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2442} INFO -  at 3.0s,\testimator lgbm's best error=0.1583,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:17] {2258} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2442} INFO -  at 3.3s,\testimator extra_tree's best error=0.2020,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2258} INFO - iteration 20, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2442} INFO -  at 3.5s,\testimator rf's best error=0.2177,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2258} INFO - iteration 21, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2442} INFO -  at 3.7s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2258} INFO - iteration 22, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2442} INFO -  at 4.0s,\testimator xgboost's best error=0.1762,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2258} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2442} INFO -  at 4.1s,\testimator lgbm's best error=0.1583,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:18] {2258} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:19] {2442} INFO -  at 4.4s,\testimator rf's best error=0.2054,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:19] {2258} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:19] {2442} INFO -  at 4.6s,\testimator extra_tree's best error=0.2020,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:19] {2258} INFO - iteration 26, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:19] {2442} INFO -  at 4.9s,\testimator sgd's best error=0.3199,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:19] {2258} INFO - iteration 27, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 5.1s,\testimator rf's best error=0.1975,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 5.5s,\testimator extra_tree's best error=0.2020,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 29, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 5.6s,\testimator sgd's best error=0.3199,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 30, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 5.7s,\testimator sgd's best error=0.3199,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 5.9s,\testimator lgbm's best error=0.1583,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 6.0s,\testimator lgbm's best error=0.1583,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2442} INFO -  at 6.1s,\testimator lgbm's best error=0.1583,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:20] {2258} INFO - iteration 34, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2442} INFO -  at 6.2s,\testimator sgd's best error=0.2301,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2258} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2442} INFO -  at 6.3s,\testimator lgbm's best error=0.1583,\tbest estimator lgbm's best error=0.1583\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2258} INFO - iteration 36, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2442} INFO -  at 6.6s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2258} INFO - iteration 37, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2442} INFO -  at 6.7s,\testimator sgd's best error=0.2301,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2258} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2442} INFO -  at 6.9s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:21] {2258} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2442} INFO -  at 7.1s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2258} INFO - iteration 40, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2442} INFO -  at 7.5s,\testimator rf's best error=0.1852,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2258} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2442} INFO -  at 7.8s,\testimator extra_tree's best error=0.2020,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2258} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2442} INFO -  at 8.0s,\testimator extra_tree's best error=0.2020,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:22] {2258} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2442} INFO -  at 8.2s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2258} INFO - iteration 44, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2442} INFO -  at 8.5s,\testimator extra_tree's best error=0.1964,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2258} INFO - iteration 45, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2442} INFO -  at 8.6s,\testimator sgd's best error=0.2233,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2258} INFO - iteration 46, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2442} INFO -  at 9.1s,\testimator sgd's best error=0.2233,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:23] {2258} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2442} INFO -  at 9.4s,\testimator rf's best error=0.1762,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2258} INFO - iteration 48, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2442} INFO -  at 9.5s,\testimator sgd's best error=0.2110,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2258} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2442} INFO -  at 9.6s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2258} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2442} INFO -  at 9.9s,\testimator rf's best error=0.1762,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2258} INFO - iteration 51, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2442} INFO -  at 10.0s,\testimator sgd's best error=0.2110,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:24] {2258} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2442} INFO -  at 10.4s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2258} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2442} INFO -  at 10.6s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2258} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2442} INFO -  at 10.7s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2258} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2442} INFO -  at 10.8s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2258} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2442} INFO -  at 11.1s,\testimator extra_tree's best error=0.1964,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:25] {2258} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:26] {2442} INFO -  at 11.4s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:26] {2258} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:26] {2442} INFO -  at 11.8s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:26] {2258} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:26] {2442} INFO -  at 12.1s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:26] {2258} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2442} INFO -  at 12.1s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2258} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2442} INFO -  at 12.4s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2258} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2442} INFO -  at 12.5s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2258} INFO - iteration 63, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2442} INFO -  at 12.8s,\testimator extra_tree's best error=0.1964,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2258} INFO - iteration 64, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2442} INFO -  at 13.0s,\testimator sgd's best error=0.2110,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:27] {2258} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2442} INFO -  at 13.1s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2258} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2442} INFO -  at 13.4s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2258} INFO - iteration 67, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2442} INFO -  at 13.5s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2258} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2442} INFO -  at 13.8s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2258} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2442} INFO -  at 13.8s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2258} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2442} INFO -  at 14.1s,\testimator extra_tree's best error=0.1841,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:28] {2258} INFO - iteration 71, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2442} INFO -  at 14.3s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2258} INFO - iteration 72, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2442} INFO -  at 14.5s,\testimator extra_tree's best error=0.1841,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2258} INFO - iteration 73, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2442} INFO -  at 14.6s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2258} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2442} INFO -  at 14.9s,\testimator extra_tree's best error=0.1807,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2258} INFO - iteration 75, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2442} INFO -  at 15.0s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:29] {2258} INFO - iteration 76, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2442} INFO -  at 15.3s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2258} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2442} INFO -  at 15.7s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2258} INFO - iteration 78, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2442} INFO -  at 15.9s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2258} INFO - iteration 79, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2442} INFO -  at 16.1s,\testimator extra_tree's best error=0.1807,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:30] {2258} INFO - iteration 80, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2442} INFO -  at 16.3s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2258} INFO - iteration 81, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2442} INFO -  at 16.4s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2258} INFO - iteration 82, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2442} INFO -  at 16.7s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2258} INFO - iteration 83, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2442} INFO -  at 16.8s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:31] {2258} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2442} INFO -  at 17.1s,\testimator extra_tree's best error=0.1762,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2258} INFO - iteration 85, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2442} INFO -  at 17.3s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2258} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2442} INFO -  at 17.6s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2258} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2442} INFO -  at 17.9s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:32] {2258} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:33] {2442} INFO -  at 18.1s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:33] {2258} INFO - iteration 89, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:33] {2442} INFO -  at 18.5s,\testimator rf's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:33] {2258} INFO - iteration 90, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:33] {2442} INFO -  at 18.7s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:33] {2258} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2442} INFO -  at 19.1s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2258} INFO - iteration 92, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2442} INFO -  at 19.2s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2258} INFO - iteration 93, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2442} INFO -  at 19.5s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2258} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2442} INFO -  at 19.8s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2258} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2442} INFO -  at 19.9s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:34] {2258} INFO - iteration 96, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:35] {2442} INFO -  at 20.3s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:35] {2258} INFO - iteration 97, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:35] {2442} INFO -  at 20.6s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:35] {2258} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:35] {2442} INFO -  at 20.9s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:35] {2258} INFO - iteration 99, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2442} INFO -  at 21.2s,\testimator rf's best error=0.1661,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2258} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2442} INFO -  at 21.3s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2258} INFO - iteration 101, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2442} INFO -  at 21.3s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2258} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2442} INFO -  at 21.7s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2258} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2442} INFO -  at 21.7s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2258} INFO - iteration 104, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2442} INFO -  at 22.0s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:36] {2258} INFO - iteration 105, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2442} INFO -  at 22.3s,\testimator rf's best error=0.1661,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2258} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2442} INFO -  at 22.6s,\testimator xgboost's best error=0.1582,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2258} INFO - iteration 107, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2442} INFO -  at 22.7s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2258} INFO - iteration 108, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2442} INFO -  at 23.0s,\testimator rf's best error=0.1661,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2258} INFO - iteration 109, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2442} INFO -  at 23.1s,\testimator sgd's best error=0.2065,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:37] {2258} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2442} INFO -  at 23.5s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2258} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2442} INFO -  at 23.5s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2258} INFO - iteration 112, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2442} INFO -  at 23.6s,\testimator sgd's best error=0.2020,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2258} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2442} INFO -  at 23.9s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2258} INFO - iteration 114, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2442} INFO -  at 24.1s,\testimator sgd's best error=0.2020,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:38] {2258} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2442} INFO -  at 24.2s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2258} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2442} INFO -  at 24.3s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2258} INFO - iteration 117, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2442} INFO -  at 24.6s,\testimator sgd's best error=0.2020,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2258} INFO - iteration 118, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2442} INFO -  at 24.9s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2258} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2442} INFO -  at 25.0s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:39] {2258} INFO - iteration 120, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:40] {2442} INFO -  at 25.4s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:40] {2258} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:40] {2442} INFO -  at 25.7s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:40] {2258} INFO - iteration 122, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:40] {2442} INFO -  at 25.8s,\testimator sgd's best error=0.2020,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:40] {2258} INFO - iteration 123, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.1s,\testimator extra_tree's best error=0.1684,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 124, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.3s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.4s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.4s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.5s,\testimator lgbm's best error=0.1583,\tbest estimator xgboost's best error=0.1582\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 128, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.8s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 129, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2442} INFO -  at 26.9s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:41] {2258} INFO - iteration 130, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2442} INFO -  at 27.2s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2258} INFO - iteration 131, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2442} INFO -  at 27.5s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2258} INFO - iteration 132, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2442} INFO -  at 27.7s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2258} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2442} INFO -  at 27.8s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2258} INFO - iteration 134, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2442} INFO -  at 28.1s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:42] {2258} INFO - iteration 135, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2442} INFO -  at 28.3s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2258} INFO - iteration 136, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2442} INFO -  at 28.5s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2258} INFO - iteration 137, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2442} INFO -  at 28.8s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2258} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2442} INFO -  at 28.9s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2258} INFO - iteration 139, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2442} INFO -  at 29.0s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:43] {2258} INFO - iteration 140, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2442} INFO -  at 29.2s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2258} INFO - iteration 141, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2442} INFO -  at 29.3s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2258} INFO - iteration 142, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2442} INFO -  at 29.7s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2258} INFO - iteration 143, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2442} INFO -  at 29.8s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:44] {2258} INFO - iteration 144, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.2s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.4s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.5s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.6s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.7s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.8s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2442} INFO -  at 30.8s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:45] {2258} INFO - iteration 151, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2442} INFO -  at 31.1s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2258} INFO - iteration 152, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2442} INFO -  at 31.6s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2258} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2442} INFO -  at 31.8s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2258} INFO - iteration 154, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2442} INFO -  at 31.9s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2258} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2442} INFO -  at 32.0s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2258} INFO - iteration 156, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2442} INFO -  at 32.1s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:46] {2258} INFO - iteration 157, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:47] {2442} INFO -  at 32.3s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:47] {2258} INFO - iteration 158, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:47] {2442} INFO -  at 32.7s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:47] {2258} INFO - iteration 159, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:47] {2442} INFO -  at 33.0s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:47] {2258} INFO - iteration 160, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2442} INFO -  at 33.1s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2258} INFO - iteration 161, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2442} INFO -  at 33.5s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2258} INFO - iteration 162, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2442} INFO -  at 33.8s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2258} INFO - iteration 163, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2442} INFO -  at 33.9s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:48] {2258} INFO - iteration 164, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:49] {2442} INFO -  at 34.1s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:49] {2258} INFO - iteration 165, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:49] {2442} INFO -  at 34.5s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:49] {2258} INFO - iteration 166, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:49] {2442} INFO -  at 34.8s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:49] {2258} INFO - iteration 167, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2442} INFO -  at 35.3s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2258} INFO - iteration 168, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2442} INFO -  at 35.4s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2258} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2442} INFO -  at 35.5s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2258} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2442} INFO -  at 35.6s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2258} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2442} INFO -  at 35.6s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2258} INFO - iteration 172, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2442} INFO -  at 35.9s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:50] {2258} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:51] {2442} INFO -  at 36.2s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:51] {2258} INFO - iteration 174, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:51] {2442} INFO -  at 36.7s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:51] {2258} INFO - iteration 175, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:51] {2442} INFO -  at 36.9s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:51] {2258} INFO - iteration 176, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:52] {2442} INFO -  at 37.1s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:52] {2258} INFO - iteration 177, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:52] {2442} INFO -  at 37.5s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:52] {2258} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:52] {2442} INFO -  at 37.8s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:52] {2258} INFO - iteration 179, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2442} INFO -  at 38.1s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2258} INFO - iteration 180, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2442} INFO -  at 38.2s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2258} INFO - iteration 181, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2442} INFO -  at 38.6s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2258} INFO - iteration 182, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2442} INFO -  at 39.0s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2258} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2442} INFO -  at 39.1s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:53] {2258} INFO - iteration 184, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:54] {2442} INFO -  at 39.3s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:54] {2258} INFO - iteration 185, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:54] {2442} INFO -  at 39.6s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:54] {2258} INFO - iteration 186, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:54] {2442} INFO -  at 39.9s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:54] {2258} INFO - iteration 187, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2442} INFO -  at 40.1s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2258} INFO - iteration 188, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2442} INFO -  at 40.3s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2258} INFO - iteration 189, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2442} INFO -  at 40.7s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2258} INFO - iteration 190, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2442} INFO -  at 40.8s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2258} INFO - iteration 191, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2442} INFO -  at 41.0s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:55] {2258} INFO - iteration 192, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:56] {2442} INFO -  at 41.5s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:56] {2258} INFO - iteration 193, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:56] {2442} INFO -  at 41.8s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:56] {2258} INFO - iteration 194, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:56] {2442} INFO -  at 41.9s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:56] {2258} INFO - iteration 195, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.1s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.2s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 197, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.5s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 198, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.6s,\testimator sgd's best error=0.2020,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 199, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.7s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 200, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.8s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 201, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2442} INFO -  at 42.9s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:57] {2258} INFO - iteration 202, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2442} INFO -  at 43.3s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2258} INFO - iteration 203, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2442} INFO -  at 43.6s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2258} INFO - iteration 204, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2442} INFO -  at 43.7s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2258} INFO - iteration 205, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2442} INFO -  at 43.9s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:58] {2258} INFO - iteration 206, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2442} INFO -  at 44.3s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2258} INFO - iteration 207, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2442} INFO -  at 44.4s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2258} INFO - iteration 208, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2442} INFO -  at 44.8s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2258} INFO - iteration 209, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2442} INFO -  at 45.1s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:45:59] {2258} INFO - iteration 210, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2442} INFO -  at 45.3s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2258} INFO - iteration 211, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2442} INFO -  at 45.7s,\testimator extra_tree's best error=0.1684,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2258} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2442} INFO -  at 46.0s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2258} INFO - iteration 213, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2442} INFO -  at 46.0s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:00] {2258} INFO - iteration 214, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2442} INFO -  at 46.1s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2258} INFO - iteration 215, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2442} INFO -  at 46.5s,\testimator rf's best error=0.1560,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2258} INFO - iteration 216, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2442} INFO -  at 46.6s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2258} INFO - iteration 217, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2442} INFO -  at 46.7s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2258} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2442} INFO -  at 46.8s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2258} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2442} INFO -  at 46.9s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:01] {2258} INFO - iteration 220, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 47.1s,\testimator xgboost's best error=0.1582,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 221, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 47.2s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 222, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 47.3s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 223, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 47.5s,\testimator sgd's best error=0.1885,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 224, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 47.6s,\testimator lgbm's best error=0.1583,\tbest estimator rf's best error=0.1560\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 47.7s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 226, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2442} INFO -  at 48.0s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:02] {2258} INFO - iteration 227, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2442} INFO -  at 48.1s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2258} INFO - iteration 228, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2442} INFO -  at 48.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2258} INFO - iteration 229, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2442} INFO -  at 48.5s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2258} INFO - iteration 230, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2442} INFO -  at 48.6s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2258} INFO - iteration 231, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2442} INFO -  at 49.0s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:03] {2258} INFO - iteration 232, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2442} INFO -  at 49.1s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2258} INFO - iteration 233, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2442} INFO -  at 49.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2258} INFO - iteration 234, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2442} INFO -  at 49.3s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2258} INFO - iteration 235, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2442} INFO -  at 49.6s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2258} INFO - iteration 236, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2442} INFO -  at 50.0s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:04] {2258} INFO - iteration 237, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:05] {2442} INFO -  at 50.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:05] {2258} INFO - iteration 238, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:05] {2442} INFO -  at 50.6s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:05] {2258} INFO - iteration 239, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:05] {2442} INFO -  at 50.8s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:05] {2258} INFO - iteration 240, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2442} INFO -  at 51.2s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2258} INFO - iteration 241, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2442} INFO -  at 51.3s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2258} INFO - iteration 242, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2442} INFO -  at 51.6s,\testimator extra_tree's best error=0.1684,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2258} INFO - iteration 243, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2442} INFO -  at 51.9s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2258} INFO - iteration 244, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2442} INFO -  at 52.0s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:06] {2258} INFO - iteration 245, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2442} INFO -  at 52.4s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2258} INFO - iteration 246, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2442} INFO -  at 52.6s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2258} INFO - iteration 247, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2442} INFO -  at 53.0s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2258} INFO - iteration 248, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2442} INFO -  at 53.1s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:07] {2258} INFO - iteration 249, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2442} INFO -  at 53.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2258} INFO - iteration 250, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2442} INFO -  at 53.5s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2258} INFO - iteration 251, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2442} INFO -  at 53.6s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2258} INFO - iteration 252, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2442} INFO -  at 53.9s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2258} INFO - iteration 253, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2442} INFO -  at 54.0s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:08] {2258} INFO - iteration 254, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2442} INFO -  at 54.1s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2258} INFO - iteration 255, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2442} INFO -  at 54.2s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2258} INFO - iteration 256, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2442} INFO -  at 54.3s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2258} INFO - iteration 257, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2442} INFO -  at 54.6s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2258} INFO - iteration 258, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2442} INFO -  at 54.7s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:09] {2258} INFO - iteration 259, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:10] {2442} INFO -  at 55.2s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:10] {2258} INFO - iteration 260, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:10] {2442} INFO -  at 55.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:10] {2258} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:10] {2442} INFO -  at 55.7s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:10] {2258} INFO - iteration 262, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2442} INFO -  at 56.1s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2258} INFO - iteration 263, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2442} INFO -  at 56.4s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2258} INFO - iteration 264, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2442} INFO -  at 56.9s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2258} INFO - iteration 265, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2442} INFO -  at 57.0s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:11] {2258} INFO - iteration 266, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2442} INFO -  at 57.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2258} INFO - iteration 267, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2442} INFO -  at 57.2s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2258} INFO - iteration 268, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2442} INFO -  at 57.4s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2258} INFO - iteration 269, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2442} INFO -  at 57.5s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2258} INFO - iteration 270, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2442} INFO -  at 57.9s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:12] {2258} INFO - iteration 271, current learner extra_tree\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2442} INFO -  at 58.3s,\testimator extra_tree's best error=0.1661,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2258} INFO - iteration 272, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2442} INFO -  at 58.6s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2258} INFO - iteration 273, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2442} INFO -  at 58.8s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2258} INFO - iteration 274, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2442} INFO -  at 59.1s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:13] {2258} INFO - iteration 275, current learner xgboost\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2442} INFO -  at 59.3s,\testimator xgboost's best error=0.1582,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2258} INFO - iteration 276, current learner rf\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2442} INFO -  at 59.6s,\testimator rf's best error=0.1560,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2258} INFO - iteration 277, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2442} INFO -  at 59.8s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2258} INFO - iteration 278, current learner lgbm\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2442} INFO -  at 59.9s,\testimator lgbm's best error=0.1526,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2258} INFO - iteration 279, current learner sgd\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2442} INFO -  at 60.0s,\testimator sgd's best error=0.1885,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:14] {2258} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 02-16 15:46:15] {2442} INFO -  at 60.2s,\testimator xgb_limitdepth's best error=0.2099,\tbest estimator lgbm's best error=0.1526\n",
      "[flaml.automl.logger: 02-16 15:46:15] {2582} INFO - [('lgbm', {'n_jobs': -1, 'n_estimators': 16, 'num_leaves': 19, 'min_child_samples': 7, 'learning_rate': np.float64(0.41587884609282355), 'colsample_bytree': np.float64(0.8334793666447552), 'reg_alpha': np.float64(1.329638867774165), 'reg_lambda': np.float64(0.26166563816625876), 'max_bin': 1023, 'verbose': -1}), ('rf', {'n_jobs': -1, 'n_estimators': 12, 'max_features': np.float64(0.4177905104559841), 'criterion': np.str_('entropy'), 'max_leaf_nodes': 27, 'random_state': 12032022, 'verbose': 0}), ('xgboost', {'n_jobs': -1, 'n_estimators': 32, 'max_leaves': 4, 'min_child_weight': np.float64(1.2498964566809219), 'learning_rate': np.float64(0.3574837022388901), 'subsample': np.float64(0.9773266280674643), 'colsample_bylevel': np.float64(0.9705283362807284), 'colsample_bytree': np.float64(0.8561269216168275), 'reg_alpha': np.float64(0.0021694711024901254), 'reg_lambda': np.float64(4.620219690690227), 'max_depth': 0, 'grow_policy': 'lossguide', 'tree_method': 'hist', 'verbosity': 0}), ('extra_tree', {'n_jobs': -1, 'n_estimators': 31, 'max_features': 0.1, 'criterion': np.str_('gini'), 'max_leaf_nodes': 61, 'random_state': 12032022, 'verbose': 0}), ('sgd', {'n_jobs': -1, 'penalty': np.str_('None'), 'alpha': np.float64(3.814357201648409e-05), 'epsilon': 0.1, 'learning_rate': np.str_('constant'), 'eta0': 0.1, 'average': False, 'loss': np.str_('modified_huber'), 'tol': 0.0001}), ('xgb_limitdepth', {'n_jobs': -1, 'n_estimators': 10, 'max_depth': 6, 'min_child_weight': np.float64(0.9999999999999993), 'learning_rate': np.float64(0.29999999999999993), 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': np.float64(0.0009765625), 'reg_lambda': np.float64(1.0), 'verbosity': 0})]\n",
      "[flaml.automl.logger: 02-16 15:46:15] {2625} INFO - Building ensemble with tuned estimators\n",
      "[flaml.automl.logger: 02-16 15:46:17] {2631} INFO - ensemble: StackingClassifier(estimators=[('lgbm',\n",
      "                                <flaml.automl.model.LGBMEstimator object at 0x118594cb0>),\n",
      "                               ('rf',\n",
      "                                <flaml.automl.model.RandomForestEstimator object at 0x118596a20>),\n",
      "                               ('xgboost',\n",
      "                                <flaml.automl.model.XGBoostSklearnEstimator object at 0x1185940b0>),\n",
      "                               ('extra_tree',\n",
      "                                <flaml.automl.model.ExtraTreesEstimator object at 0x118596510>),\n",
      "                               ('sgd',\n",
      "                                <flaml.automl.model.SGDEstimator object at 0x118595af0>),\n",
      "                               ('xgb_limitdepth',\n",
      "                                <flaml.automl.model.XGBoostLimitDepthEstimator object at 0x1185958e0>)],\n",
      "                   n_jobs=1, passthrough=True)\n",
      "[flaml.automl.logger: 02-16 15:46:17] {1985} INFO - fit succeeded\n",
      "[flaml.automl.logger: 02-16 15:46:17] {1986} INFO - Time taken to find the best model: 47.71293592453003\n",
      "[flaml.automl.logger: 02-16 15:46:17] {1996} WARNING - Time taken to find the best model is 80% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshiyin/Documents/Teaching/machine-learning-for-actuarial-science/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 60,  # total running time in seconds\n",
    "    \"metric\": 'accuracy', \n",
    "                        # check the documentation for options of metrics (https://microsoft.github.io/FLAML/docs/Use-Cases/Task-Oriented-AutoML#optimization-metric)\n",
    "    \"task\": 'classification',  # task type\n",
    "    \"log_file_name\": 'airlines_experiment.log',  # flaml log file\n",
    "    \"seed\": 7654321,    # random seed\n",
    "    \"ensemble\": True,\n",
    "}\n",
    "automl.fit(X_train, y_train, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.drop(columns=['passengerid'])\n",
    "y_test_pred = automl.predict(X_test)\n",
    "df_submission = pd.concat([test['passengerid'], pd.DataFrame(y_test_pred, columns=['survived'])], axis=1)\n",
    "df_submission.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('../data/titanic/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lgbm'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 16,\n",
       " 'num_leaves': 19,\n",
       " 'min_child_samples': 7,\n",
       " 'learning_rate': np.float64(0.41587884609282355),\n",
       " 'log_max_bin': 10,\n",
       " 'colsample_bytree': np.float64(0.8334793666447552),\n",
       " 'reg_alpha': np.float64(1.329638867774165),\n",
       " 'reg_lambda': np.float64(0.26166563816625876)}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StackingClassifier' object has no attribute 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StackingClassifier' object has no attribute 'estimator'"
     ]
    }
   ],
   "source": [
    "automl.model.estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StackingClassifier' object has no attribute 'estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get feature importance values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m importances \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get feature names from the dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StackingClassifier' object has no attribute 'estimator'"
     ]
    }
   ],
   "source": [
    "# Get feature importance values\n",
    "importances = automl.model.estimator.feature_importances_\n",
    "# Get feature names from the dataset\n",
    "feature_names = X_train.columns\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "# Sort by importance (highest first)\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size for better readability\n",
    "plt.bar(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "\n",
    "# Rotate feature names for readability\n",
    "plt.xticks(rotation=45, ha='right')  # Tilt labels 45 degrees and align to the right\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Feature Name')\n",
    "plt.ylabel('Importance Score')\n",
    "plt.title('Feature Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
