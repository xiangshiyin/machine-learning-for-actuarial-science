{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Click the icon below to open this notebook in Colab**)\n",
    "\n",
    "[![Open InColab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiangshiyin/machine-learning-for-actuarial-science/blob/main/2025-spring/week06/notebook/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In our last class, we explored the Titanic dataset, examined it from multiple perspectives, and applied various feature engineering techniques to enhance its explanatory variables. Today, we will continue working with the Titanic dataset, focusing on model training and evaluation techniques to gain deeper insights into predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic/data\n",
    "- **The Titanic** https://en.wikipedia.org/wiki/Titanic\n",
    "\n",
    "| Variable   | Definition                                | Key                                  |\n",
    "|------------|-------------------------------------------|--------------------------------------|\n",
    "| survival   | Survival                                 | 0 = No, 1 = Yes                     |\n",
    "| pclass     | Ticket class                             | 1 = 1st, 2 = 2nd, 3 = 3rd           |\n",
    "| sex        | Sex                                      |                                      |\n",
    "| Age        | Age in years                             |                                      |\n",
    "| sibsp      | # of siblings / spouses aboard the Titanic |                                      |\n",
    "| parch      | # of parents / children aboard the Titanic |                                      |\n",
    "| ticket     | Ticket number                            |                                      |\n",
    "| fare       | Passenger fare                           |                                      |\n",
    "| cabin      | Cabin number                             |                                      |\n",
    "| embarked   | Port of Embarkation                     | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/titanic/train.csv')\n",
    "test = pd.read_csv('../data/titanic/test.csv')\n",
    "\n",
    "# convert all column names to lower cases\n",
    "train.columns = train.columns.str.lower()\n",
    "test.columns = test.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                name     sex   age  sibsp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   parch            ticket     fare cabin embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Streamline the data transformations\n",
    "\n",
    "Here are the data exploration and transformation strategies we used so far:\n",
    "* Quick survey across key variables\n",
    "* Detect and address data anomalies\n",
    "  * Missing values\n",
    "  * Outliers\n",
    "* Feature engineering\n",
    "  * Encode categorical variables\n",
    "  * Normalize numerical variables\n",
    "  * Create new features with stronger predictive power\n",
    "\n",
    "Data exploration process is typically iterative and complex. Once we have a good understanding of the data and some potential strategies to apply in the feature engineering process, we need to make sure these transformation strategies can be easily and consistently applied to new datasets, such as the test set and new batches of data for model retraining. This requires a systematic approach to streamline the data transformations so that we don't need to start from scratch and repeat the same steps for each new dataset. This is especially important in the real-world scenario where we want to productionalize and automate the data transformation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_num_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values in numerical columns of a DataFrame using the median of each column.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The DataFrame to impute missing values in.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select only the numerical columns\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Impute missing values with the median of each column\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age              0\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = impute_missing_num_values(train)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables could have missing values too\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html\n",
    "\n",
    "def impute_missing_cat_values(df, ignore_list):\n",
    "    \"\"\"\n",
    "    Impute missing categorical values with the most frequent value.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        ignore_list (list): List of column names to ignore.    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with imputed missing categorical values.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ignore_list:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passengerid      0\n",
       "survived         0\n",
       "pclass           0\n",
       "name             0\n",
       "sex              0\n",
       "age              0\n",
       "sibsp            0\n",
       "parch            0\n",
       "ticket           0\n",
       "fare             0\n",
       "cabin          687\n",
       "embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = impute_missing_cat_values(train, ignore_list=['cabin'])\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ **Attention:** We will treat the missing values in `cabin` in the feature engineering step!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Encode categorical features\n",
    "- Normalize numerical features\n",
    "- Create new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'sex', 'ticket', 'cabin', 'embarked']\n"
     ]
    }
   ],
   "source": [
    "# The categorical variables in the datasets\n",
    "\n",
    "cat_cols = [\n",
    "    col\n",
    "    for col in train.columns if train[col].dtype == \"object\"\n",
    "] \n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply onehot encoding to the categorical columns\n",
    "# use the sklearn library\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def onehot_encode(df, ignore_list):\n",
    "    cat_cols = [\n",
    "        col for col in df.columns if col not in ignore_list and df[col].dtype == 'object'\n",
    "    ]\n",
    "    encoder = OneHotEncoder()\n",
    "    encoded = encoder.fit_transform(df[cat_cols])\n",
    "    encoded_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(cat_cols))\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    df = df.drop(cat_cols, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = onehot_encode(train, ignore_list=['cabin', 'name', 'ticket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform numeric features, log transform `fare`\n",
    "import numpy as np\n",
    "\n",
    "def log_transform(df, features, drop=False):\n",
    "    for feature in features:\n",
    "        df[feature+'_log'] = np.log1p(df[feature]) \n",
    "    if drop:\n",
    "        df = df.drop(features, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'age', 'sibsp', 'parch',\n",
       "       'ticket', 'fare', 'cabin', 'sex_female', 'sex_male', 'embarked_C',\n",
       "       'embarked_Q', 'embarked_S', 'fare_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = log_transform(train, features=['fare'])\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "import re\n",
    "\n",
    "def create_features(df):\n",
    "    df['has_cabin'] = df['cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = df['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['title'] = df['name'].apply(lambda x: re.search('([A-Z][a-z]+)\\\\.', x).group(1))\n",
    "    df['cabin'] = df['cabin'].fillna('U0')\n",
    "    df['deck'] = df['cabin'].apply(lambda x: re.search('([A-Z]+)', x).group(1))\n",
    "    df['name_len_cat'] = df['name'].apply(lambda x: 0 if len(x) <= 23 else 1 if len(x) <= 28 else 2 if len(x) <= 40 else 3)\n",
    "    df['age_cat'] = df['age'].apply(lambda x: 0 if x <= 14 else 1 if x <= 30 else 2 if x <= 40 else 3 if x <= 50 else 4 if x <= 60 else 5)\n",
    "    df['fare_log_cat'] = df['fare_log'].apply(lambda x: 0 if x <= 2.7 else 1 if x <= 3.2 else 2 if x <= 3.6 else 3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'age', 'sibsp', 'parch',\n",
       "       'ticket', 'fare', 'cabin', 'sex_female', 'sex_male', 'embarked_C',\n",
       "       'embarked_Q', 'embarked_S', 'fare_log', 'has_cabin', 'family_size',\n",
       "       'is_alone', 'title', 'deck', 'name_len_cat', 'age_cat', 'fare_log_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = create_features(train)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def impute_missing_num_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values in numerical columns of a DataFrame using the median of each column.\n",
    "\n",
    "    Args:\n",
    "    df (pandas.DataFrame): The DataFrame to impute missing values in.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Select only the numerical columns\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    # Impute missing values with the median of each column\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    return df\n",
    "\n",
    "def impute_missing_cat_values(df, ignore_list):\n",
    "    \"\"\"\n",
    "    Impute missing categorical values with the most frequent value.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        ignore_list (list): List of column names to ignore.    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with imputed missing categorical values.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col not in ignore_list:\n",
    "            if df[col].dtype == 'object':\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    return df\n",
    "\n",
    "def log_transform(df, features, drop=False):\n",
    "    for feature in features:\n",
    "        df[feature+'_log'] = np.log1p(df[feature]) \n",
    "    if drop:\n",
    "        df = df.drop(features, axis=1)\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    df['has_cabin'] = df['cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "    df['is_alone'] = df['family_size'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    df['title'] = df['name'].apply(lambda x: re.search('([A-Z][a-z]+)\\\\.', x).group(1))\n",
    "    df['cabin'] = df['cabin'].fillna('U0')\n",
    "    df['deck'] = df['cabin'].apply(lambda x: re.search('([A-Z]+)', x).group(1))\n",
    "    df['name_len_cat'] = df['name'].apply(lambda x: 0 if len(x) <= 23 else 1 if len(x) <= 28 else 2 if len(x) <= 40 else 3)\n",
    "    df['age_cat'] = df['age'].apply(lambda x: 0 if x <= 14 else 1 if x <= 30 else 2 if x <= 40 else 3 if x <= 50 else 4 if x <= 60 else 5)\n",
    "    df['fare_log_cat'] = df['fare_log'].apply(lambda x: 0 if x <= 2.7 else 1 if x <= 3.2 else 2 if x <= 3.6 else 3)\n",
    "    return df\n",
    "\n",
    "def load_data():\n",
    "    train = pd.read_csv('../data/titanic/train.csv')\n",
    "    test = pd.read_csv('../data/titanic/test.csv')\n",
    "    # convert all column names to lower cases\n",
    "    train.columns = train.columns.str.lower()\n",
    "    test.columns = test.columns.str.lower()    \n",
    "    return train, test\n",
    "\n",
    "def transform_data(df, encoder=None):\n",
    "    df = impute_missing_num_values(df)\n",
    "    df = impute_missing_cat_values(df, ['cabin', 'embarked'])\n",
    "    df = log_transform(df, ['fare'])\n",
    "    df = create_features(df)\n",
    "    \n",
    "    cat_attributes = ['sex', 'embarked', 'title', 'deck']\n",
    "    if not encoder:\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "        encoder.fit(df[cat_attributes])\n",
    "    encoded = encoder.transform(df[cat_attributes])\n",
    "    df = pd.concat([df, pd.DataFrame(encoded, columns=encoder.get_feature_names_out(cat_attributes))], axis=1)\n",
    "    # drop columns that are not needed\n",
    "    df = df.drop([\n",
    "        'name', 'ticket', 'cabin', 'fare'\n",
    "        # , 'age', 'fare', 'sibsp', 'parch'\n",
    "    ] + cat_attributes, axis=1)\n",
    "    return df, encoder\n",
    "\n",
    "train, test = load_data()\n",
    "train, encoder = transform_data(train)\n",
    "test, _ = transform_data(test, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>fare_log</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>name_len_cat</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>fare_log_cat</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>embarked_nan</th>\n",
       "      <th>title_Capt</th>\n",
       "      <th>title_Col</th>\n",
       "      <th>title_Countess</th>\n",
       "      <th>title_Don</th>\n",
       "      <th>title_Dr</th>\n",
       "      <th>title_Jonkheer</th>\n",
       "      <th>title_Lady</th>\n",
       "      <th>title_Major</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mlle</th>\n",
       "      <th>title_Mme</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Ms</th>\n",
       "      <th>title_Rev</th>\n",
       "      <th>title_Sir</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.110213</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.280593</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived  pclass  fare_log  has_cabin  family_size  is_alone  \\\n",
       "0            1         0       3  2.110213          0            2         0   \n",
       "1            2         1       1  4.280593          1            2         0   \n",
       "\n",
       "   name_len_cat  age_cat  fare_log_cat  sex_female  sex_male  embarked_C  \\\n",
       "0             0        1             0         0.0       1.0         0.0   \n",
       "1             3        2             3         1.0       0.0         1.0   \n",
       "\n",
       "   embarked_Q  embarked_S  embarked_nan  title_Capt  title_Col  \\\n",
       "0         0.0         1.0           0.0         0.0        0.0   \n",
       "1         0.0         0.0           0.0         0.0        0.0   \n",
       "\n",
       "   title_Countess  title_Don  title_Dr  title_Jonkheer  title_Lady  \\\n",
       "0             0.0        0.0       0.0             0.0         0.0   \n",
       "1             0.0        0.0       0.0             0.0         0.0   \n",
       "\n",
       "   title_Major  title_Master  title_Miss  title_Mlle  title_Mme  title_Mr  \\\n",
       "0          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "1          0.0           0.0         0.0         0.0        0.0       0.0   \n",
       "\n",
       "   title_Mrs  title_Ms  title_Rev  title_Sir  deck_A  deck_B  deck_C  deck_D  \\\n",
       "0        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "1        1.0       0.0        0.0        0.0     0.0     0.0     1.0     0.0   \n",
       "\n",
       "   deck_E  deck_F  deck_G  deck_T  deck_U  \n",
       "0     0.0     0.0     0.0     0.0     1.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 41)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>pclass</th>\n",
       "      <th>fare_log</th>\n",
       "      <th>has_cabin</th>\n",
       "      <th>family_size</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>name_len_cat</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>fare_log_cat</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_C</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>embarked_nan</th>\n",
       "      <th>title_Capt</th>\n",
       "      <th>title_Col</th>\n",
       "      <th>title_Countess</th>\n",
       "      <th>title_Don</th>\n",
       "      <th>title_Dr</th>\n",
       "      <th>title_Jonkheer</th>\n",
       "      <th>title_Lady</th>\n",
       "      <th>title_Major</th>\n",
       "      <th>title_Master</th>\n",
       "      <th>title_Miss</th>\n",
       "      <th>title_Mlle</th>\n",
       "      <th>title_Mme</th>\n",
       "      <th>title_Mr</th>\n",
       "      <th>title_Mrs</th>\n",
       "      <th>title_Ms</th>\n",
       "      <th>title_Rev</th>\n",
       "      <th>title_Sir</th>\n",
       "      <th>deck_A</th>\n",
       "      <th>deck_B</th>\n",
       "      <th>deck_C</th>\n",
       "      <th>deck_D</th>\n",
       "      <th>deck_E</th>\n",
       "      <th>deck_F</th>\n",
       "      <th>deck_G</th>\n",
       "      <th>deck_T</th>\n",
       "      <th>deck_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>2.178064</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>2.369075</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  pclass  fare_log  has_cabin  family_size  is_alone  \\\n",
       "0          892       3  2.178064          0            1         1   \n",
       "1          893       3  2.079442          0            2         0   \n",
       "2          894       2  2.369075          0            1         1   \n",
       "\n",
       "   name_len_cat  age_cat  fare_log_cat  sex_female  sex_male  embarked_C  \\\n",
       "0             0        2             0         0.0       1.0         0.0   \n",
       "1             2        3             0         1.0       0.0         0.0   \n",
       "2             1        5             0         0.0       1.0         0.0   \n",
       "\n",
       "   embarked_Q  embarked_S  embarked_nan  title_Capt  title_Col  \\\n",
       "0         1.0         0.0           0.0         0.0        0.0   \n",
       "1         0.0         1.0           0.0         0.0        0.0   \n",
       "2         1.0         0.0           0.0         0.0        0.0   \n",
       "\n",
       "   title_Countess  title_Don  title_Dr  title_Jonkheer  title_Lady  \\\n",
       "0             0.0        0.0       0.0             0.0         0.0   \n",
       "1             0.0        0.0       0.0             0.0         0.0   \n",
       "2             0.0        0.0       0.0             0.0         0.0   \n",
       "\n",
       "   title_Major  title_Master  title_Miss  title_Mlle  title_Mme  title_Mr  \\\n",
       "0          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "1          0.0           0.0         0.0         0.0        0.0       0.0   \n",
       "2          0.0           0.0         0.0         0.0        0.0       1.0   \n",
       "\n",
       "   title_Mrs  title_Ms  title_Rev  title_Sir  deck_A  deck_B  deck_C  deck_D  \\\n",
       "0        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "1        1.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "2        0.0       0.0        0.0        0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   deck_E  deck_F  deck_G  deck_T  deck_U  \n",
       "0     0.0     0.0     0.0     0.0     1.0  \n",
       "1     0.0     0.0     0.0     0.0     1.0  \n",
       "2     0.0     0.0     0.0     0.0     1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a simple logistic regression model to predict the survival label\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(\n",
    "    train.drop(columns=['survived', 'passengerid']), # everything except the survival label\n",
    "    train['survived'] # the survival label\n",
    ")\n",
    "\n",
    "pred = lr.predict(test.drop(columns=['passengerid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passengerid  survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission = pd.concat([test['passengerid'], pd.DataFrame(pred, columns=['survived'])], axis=1)\n",
    "df_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('../data/titanic/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class AppendNewFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "        return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]a\n",
    "\n",
    "num_attributes = ['pclass', 'age', 'family_size', 'fare', 'fare_log', 'has_cabin', 'is_alone', 'name_len_cat', 'age_cat', 'fare_log_cat']\n",
    "cat_attributes = ['sex', 'embarked', 'title', 'deck']\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', AppendNewFeatures()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "    ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
