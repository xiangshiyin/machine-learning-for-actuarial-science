{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Click the icon below to open this notebook in Colab**)\n",
    "\n",
    "[![Open InColab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xiangshiyin/machine-learning-for-actuarial-science/blob/main/2025-spring/week15/notebook/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "data = \"This is a simple example to demonstrate removing stopwords using NLTK.\"\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original text: {data}\")\n",
    "print(f\"Tokenized text: {\"|\".join(tokenized_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokenized_data = [\n",
    "    w\n",
    "    for w in tokenized_data\n",
    "    if w not in stopWords\n",
    "]\n",
    "print(f\"After removing stopwords: {filtered_tokenized_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original text: {data}\")\n",
    "print(f\"Tokenized text: {\"|\".join(tokenized_data)}\")\n",
    "print(f\"After removing stopwords: {\"|\".join(filtered_tokenized_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Sample dataset\n",
    "texts = [\n",
    "    \"I love this product\",         # positive\n",
    "    \"This is amazing\",             # positive\n",
    "    \"Very happy with the result\",  # positive\n",
    "    \"I hate this\",                 # negative\n",
    "    \"Worst experience ever\",       # negative\n",
    "    \"Not satisfied at all\"         # negative\n",
    "]\n",
    "\n",
    "labels = [1, 1, 1, 0, 0, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# 2. Convert text to bag-of-words vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# 3. Show feature names\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "\n",
    "# Download NLTK movie_reviews data\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Prepare dataset\n",
    "docs = []\n",
    "labels = []\n",
    "\n",
    "for fileid in movie_reviews.fileids():\n",
    "    docs.append(movie_reviews.raw(fileid))\n",
    "    labels.append(movie_reviews.categories(fileid)[0])  # 'pos' or 'neg'\n",
    "\n",
    "# Convert labels to binary format\n",
    "y = [1 if label == 'pos' else 0 for label in labels]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Choose a sample document from the test set\n",
    "sample_idx = 0\n",
    "sample_vector = X_test_tfidf[sample_idx]\n",
    "\n",
    "# Convert sparse vector to dense and create DataFrame\n",
    "df_features = pd.DataFrame(\n",
    "    data=sample_vector.toarray()[0],\n",
    "    index=feature_names,\n",
    "    columns=[\"tfidf\"]\n",
    ")\n",
    "\n",
    "# Filter non-zero features and sort\n",
    "df_nonzero = df_features[df_features.tfidf > 0].sort_values(by=\"tfidf\", ascending=False)\n",
    "\n",
    "# Show top 15 features by TF-IDF weight\n",
    "print(\"\\nTop TF-IDF features in sample test document:\")\n",
    "print(df_nonzero.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand-craft implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Sample corpus\n",
    "corpus = \"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "# Preprocessing: Tokenization and vocabulary building\n",
    "tokens = re.findall(r'\\b\\w+\\b', corpus.lower())\n",
    "vocab = set(tokens)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "def generate_training_data(tokens, window_size):\n",
    "    training_data = []\n",
    "    for idx, target_word in enumerate(tokens):\n",
    "        target_idx = word_to_idx[target_word]\n",
    "        context_range = list(range(max(0, idx - window_size), idx)) + \\\n",
    "                        list(range(idx + 1, min(len(tokens), idx + window_size + 1)))\n",
    "        for context_idx in context_range:\n",
    "            context_word = tokens[context_idx]\n",
    "            context_word_idx = word_to_idx[context_word]\n",
    "            training_data.append((target_idx, context_word_idx))\n",
    "    return training_data\n",
    "\n",
    "window_size = 2\n",
    "training_data = generate_training_data(tokens, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the training data\n",
    "print(f\"Corpus: {corpus}\")\n",
    "print([\n",
    "    (idx_to_word[t[0]], idx_to_word[t[1]])\n",
    "    for t in training_data\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "embedding_dim = 10\n",
    "W1 = np.random.randn(vocab_size, embedding_dim)\n",
    "W2 = np.random.randn(embedding_dim, vocab_size)\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Training parameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "num_negative_samples = 2\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for target_idx, context_idx in training_data:\n",
    "        # Positive sample\n",
    "        h = W1[target_idx]\n",
    "        u = np.dot(h, W2[:, context_idx])\n",
    "        pred = sigmoid(u)\n",
    "        error = pred - 1\n",
    "        loss += -np.log(pred + 1e-7)\n",
    "        # Gradients\n",
    "        grad_W2 = error * h\n",
    "        grad_W1 = error * W2[:, context_idx]\n",
    "        # Update weights\n",
    "        W2[:, context_idx] -= learning_rate * grad_W2\n",
    "        W1[target_idx] -= learning_rate * grad_W1\n",
    "\n",
    "        # Negative sampling\n",
    "        negative_samples = random.sample([i for i in range(vocab_size) if i != context_idx], num_negative_samples)\n",
    "        for neg_idx in negative_samples:\n",
    "            u_neg = np.dot(h, W2[:, neg_idx])\n",
    "            pred_neg = sigmoid(u_neg)\n",
    "            error_neg = pred_neg\n",
    "            loss += -np.log(1 - pred_neg + 1e-7)\n",
    "            # Gradients\n",
    "            grad_W2_neg = error_neg * h\n",
    "            grad_W1_neg = error_neg * W2[:, neg_idx]\n",
    "            # Update weights\n",
    "            W2[:, neg_idx] -= learning_rate * grad_W2_neg\n",
    "            W1[target_idx] -= learning_rate * grad_W1_neg\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve word embeddings\n",
    "word_embeddings = W1\n",
    "\n",
    "# Example: Find similar words\n",
    "def find_similar(word, top_n=3):\n",
    "    if word not in word_to_idx:\n",
    "        print(f\"'{word}' not in vocabulary.\")\n",
    "        return\n",
    "    idx = word_to_idx[word]\n",
    "    vec = word_embeddings[idx]\n",
    "    similarities = []\n",
    "    for i in range(vocab_size):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        sim = np.dot(vec, word_embeddings[i]) / (np.linalg.norm(vec) * np.linalg.norm(word_embeddings[i]))\n",
    "        similarities.append((idx_to_word[i], sim))\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    for word, sim in similarities[:top_n]:\n",
    "        print(f\"{word}: {sim:.4f}\")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\nWords similar to 'fox':\")\n",
    "find_similar('fox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With `Gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample corpus\n",
    "sentences = [\n",
    "    [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"],\n",
    "    [\"i\", \"love\", \"natural\", \"language\", \"processing\"],\n",
    "    [\"word2vec\", \"is\", \"a\", \"technique\", \"for\", \"natural\", \"language\", \"processing\"],\n",
    "    [\"the\", \"dog\", \"is\", \"lazy\", \"but\", \"the\", \"brown\", \"fox\", \"is\", \"quick\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the model\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,  # Dimensionality of the word vectors\n",
    "    window=5,         # Maximum distance between the current and predicted word\n",
    "    min_count=1,      # Ignores all words with total frequency lower than this\n",
    "    workers=4,        # Use these many worker threads to train the model\n",
    "    sg=1              # 1 for Skip-gram; 0 for CBOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar words\n",
    "similar_words = model.wv.most_similar(\"fox\", topn=3)\n",
    "print(similar_words)\n",
    "\n",
    "# Compute similarity between two words\n",
    "similarity = model.wv.similarity(\"dog\", \"fox\")\n",
    "print(f\"Similarity between 'dog' and 'fox': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "Mr. Dursley was the director of a firm called Grunnings, which made\n",
    "drills. He was a big, beefy man with hardly any neck, although he did\n",
    "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
    "nearly twice the usual amount of neck, which came in very useful as she\n",
    "spent so much of her time craning over garden fences, spying on the\n",
    "neighbors. The Dursleys had a small son called Dudley and in their\n",
    "opinion there was no finer boy anywhere.\n",
    "\n",
    "\n",
    "The Dursleys had everything they wanted, but they also had a secret, and\n",
    "their greatest fear was that somebody would discover it. They didn't\n",
    "think they could bear it if anyone found out about the Potters. Mrs.\n",
    "Potter was Mrs. Dursley's sister, but they hadn't met for several years;\n",
    "in fact, Mrs. Dursley pretended she didn't have a sister, because her\n",
    "sister and her good-for-nothing husband were as unDursleyish as it was\n",
    "possible to be. The Dursleys shuddered to think what the neighbors would\n",
    "say if the Potters arrived in the street. The Dursleys knew that the\n",
    "Potters had a small son, too, but they had never even seen him. This boy\n",
    "was another good reason for keeping the Potters away; they didn't want\n",
    "Dudley mixing with a child like that.\n",
    "\n",
    "\n",
    "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
    "starts, there was nothing about the cloudy sky outside to suggest that\n",
    "strange and mysterious things would soon be happening all over the\n",
    "country. Mr. Dursley hummed as he picked out his most boring tie for\n",
    "work, and Mrs. Dursley gossiped away happily as she wrestled a screaming\n",
    "Dudley into his high chair.\n",
    "\"\"\"\n",
    "\n",
    "sentences = [\n",
    "    gensim.utils.simple_preprocess(sentence)\n",
    "    for sentence in sample.split(\"\\n\\n\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,  # Dimensionality of the word vectors\n",
    "    window=5,         # Maximum distance between the current and predicted word\n",
    "    min_count=1,      # Ignores all words with total frequency lower than this\n",
    "    workers=4,        # Use these many worker threads to train the model\n",
    "    sg=1              # 1 for Skip-gram; 0 for CBOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar words\n",
    "similar_words = model.wv.most_similar(\"potter\", topn=3)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GLoVE`\n",
    "\n",
    "- https://nlp.stanford.edu/projects/glove/\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html#pretrained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All available models in gensim-data\n",
    "for model in gensim.downloader.info()['models'].keys():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.most_similar('twitter', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.most_similar('president', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.most_similar('usa', topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors.get_vector('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = glove_vectors.get_vector('king')\n",
    "queen = glove_vectors.get_vector('queen')\n",
    "man = glove_vectors.get_vector('man')\n",
    "woman = glove_vectors.get_vector('woman')\n",
    "\n",
    "res = king - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity = cosine_similarity(res.reshape(1, -1), queen.reshape(1, -1))\n",
    "print(f\"Similarity between queen and res: {similarity[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cosine similarity of two vectors following the linear algebra formula\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(), override=True) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"what is the capital of France?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"If there are 3 apples and you take away 2, how many in total?\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "Cooking ma po tofu is easy. First, you need to buy some tofu. Then you need to heat some oil in a pan.\n",
    "After that, you need to add the tofu to the pan. Then you need to cook the tofu. After that, you need \n",
    "to add some seasoning to the tofu. Some people might first cook some ground beef and then add the tofu.\n",
    "And that's it! You have cooked some delicious tofu. Enjoy!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. If the content contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "...\n",
    "Step N - ...\n",
    "If the content does not contain a sequence of instructions, then simply write \\\"No steps provided.\\\"\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text-to-Step transformation:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode('tiktoken is great!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, model_name: str = \"gpt-3.5-turbo\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    tokenizer = tiktoken.encoding_for_model(model_name)\n",
    "    num_tokens = len(tokenizer.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_string(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens_from_string(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn tokens into text\n",
    "tokenizer.decode([83, 1609, 5963, 374, 2294, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid prompt injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "Cooking ma po tofu is easy. First, you need to buy some tofu. Then you need to heat some oil in a pan.\n",
    "After that, you need to add the tofu to the pan. Then you need to cook the tofu. After that, you need \n",
    "to add some seasoning to the tofu. Some people might first cook some ground beef and then add the tofu.\n",
    "And that's it! You have cooked some delicious tofu. Enjoy!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. If the content contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "...\n",
    "Step N - ...\n",
    "If the content does not contain a sequence of instructions, then simply write \\\"No steps provided.\\\"\n",
    "Please provide the response in JSON format with the following keys:\n",
    "step_numbers, steps\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(\"Completion for Text-to-Step transformation:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if condition is met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control the length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please answer questions in a consistent style.\n",
    "\n",
    "Q: How can I become a kungfu master?\n",
    "A: Empty your mind, be formless. Shapeless, like water. If you put water into a cup, it becomes the cup. You put water into a bottle and it becomes the bottle. You put it in a teapot, it becomes the teapot. Now, water can flow or it can crash. Be water, my friend.\n",
    "Q: How can I become a good leader?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A math problem (coursera example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \n",
    "me a flat $100k per year, and an additional $10 / square\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about the architecture Xiangshi Yin\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interative Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about the self-attention mechanism in transformers.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = \"\"\"\n",
    "First year changing from Milorganite.....Have already spread over 3 acres once, waiting on my next shipment. This stuff spreads super easy and I am glad they increased the size of bags. We only had one issue and it is when my daughter had her basketball team over, it is good for PGF and bad.....maybe. I decided to use the spreading of fertilizer as conditioning drill, which seemed like a win/win. All the girls did well until it got to KOBI. Kobi started sprinting with the spreader and I was attempting to get her to slow down. By the time I got to her to explain why I needed an even spread on my beautiful lawn, she slipped in a giant St. Bernard turd. Unfortunately she was wearing her basketball shoes for some reason so they got ruined....but that is not the worst part. When she fell she went forward and landed face first in the spreader with all the fertilizer. Which would not have been a problem but Kobi is the most out of shape person on the team and when she began sprinting with the spreader she immediately broke out in a sweat. The PGF fertilizer stuck to her face and when she looked up it looked like a young version of the bearded lady from the carnival. After I quit laughing, I attempted to help her wash off her face. Well actually I asked her to pick up all the fertilizer she spilled first because this stuff is not cheap. Then we washed off her face but she screamed and screamed. I thought it was because of her prepubescent acne face. However, I now believe it was because PGF started to work instantly, with the moisture on her face. That was late February and her mother just called me in April and stated her daughter is growing a full beard and mustache. It was unfortunate because we had a basketball tournament and they would not let her play because they did not believe she was a girl. The hair on her face is thick and rich, which makes me think this is a great product. But you might want to keep it away from the Kobi's of the world.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring\n",
    "- Sentiment (positive/negative)\n",
    "- Identify types of emotions\n",
    "- Identify the subject of the text\n",
    "- Identify the entities (product and company)\n",
    "- Multiple tasks at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Help me identify the entities and relations present in the following product review:\n",
    "Review:\n",
    "```\n",
    "{review}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Help me identify the entities (product, company, etc.) and relations present in the following product review:\n",
    "Review:\n",
    "```\n",
    "{review}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following English text to Chinese:\n",
    "\n",
    "Hi, I would like to order a ma po tofu.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tone transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spellchecks (example from coursera) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
    "  \"Their goes my freedom. There going to bring they’re suitcases.\",  # Homonyms\n",
    "  \"Your going to need you’re notebook.\",  # Homonyms\n",
    "  \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\", # Homonyms\n",
    "  \"This phrase is to cherck chatGPT for speling abilitty\"  # spelling\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reply to Customer Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = input(\"Tell me a joke: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
