# Week 03: Machine Learning Basics
---

**Table of Content**
- [Week 03: Machine Learning Basics](#week-03-machine-learning-basics)
  - [Objectives](#objectives)
  - [Topics](#topics)
  - [Course materials](#course-materials)
  - [Suggested reading](#suggested-reading)

---
## Objectives
In this week, we will discuss about the basics of machine learning, including the different types of machine learning algorithms and their applications in different scenarios.

## Topics
Here are the topics we are going to cover
* [ ] Machine learning from 10,000 feet
  * [ ] Essentially we are estimating a function $\hat f(x)$ from a set of data $(x, y)$ so it is a good approximation of the true function $f(x)$ where $Y = f(x) + \epsilon$
  * [ ] We can get an estimation of an output $\hat Y$ from an input $x$ following the relation $\hat Y = \hat f(x)$
* [ ] Case study: Recognizing hand-written digits
* [ ] Types of machine learning algorithms and their applications


## Course materials
* slides [[link](https://docs.google.com/presentation/d/1FE2GVA-hmympPN_PnI01Zz_PRq-rP1Tvlecl1zlqx7Y/edit?usp=sharing)]

## Suggested reading
* **Chapter 1** of the book "*Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems*"
* **Chapter 2** of the book "*Introduction to Statistical Learning with Applications in Python*"
* Online resources
  * Derive the gradient of the cross-entropy loss function [[link](https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1)]